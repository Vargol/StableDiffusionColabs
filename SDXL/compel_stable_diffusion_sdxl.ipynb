{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "history_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vargol/StableDiffusionColabs/blob/main/SDXL/compel_stable_diffusion_sdxl.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using a Compel to handle prompts. Demonstrates Compel and using Diffusers to load models without loading the models text encoder and tokenizer.\n",
        "\n",
        "As usual for these examples the last cell is re-runnable, so new prompts / parameters can be used without recreating the whole environment.\n",
        "\n",
        "ATM this requires Diffusers 0.22 which isn't out yet so gets Diffusers from source."
      ],
      "metadata": {
        "id": "TwBexNYrhooy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install --quiet --upgrade git+https://github.com/huggingface/diffusers.git  transformers accelerate mediapy compel"
      ],
      "metadata": {
        "id": "ufD_d64nr08H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import mediapy as media\n",
        "import random\n",
        "import sys\n",
        "import torch\n",
        "import gc\n",
        "import time\n",
        "\n",
        "from diffusers import DiffusionPipeline, AutoencoderKL, UniPCMultistepScheduler\n",
        "from transformers import CLIPTokenizer, CLIPTextModelWithProjection, CLIPTextModel\n",
        "from compel import Compel, ReturnedEmbeddingsType\n",
        "\n",
        "refiner = None\n",
        "pipe = None\n",
        "\n",
        "vae = AutoencoderKL.from_pretrained(\"madebyollin/sdxl-vae-fp16-fix\",\n",
        "                                    torch_dtype=torch.float16,\n",
        "                                    force_upcast=False).to('cuda')\n",
        "\n",
        "\n",
        "styles = {\n",
        "\"Enhance\" : {\n",
        "\"Positive\" : \"breathtaking {prompt} . award-winning, professional, highly detailed\",\n",
        "\"Negative\" : \"ugly, deformed, noisy, blurry, distorted, grainy\",\n",
        "},\n",
        "\"Anime\" : {\n",
        "\"Positive\" : \"anime artwork {prompt} . anime style, key visual, vibrant, studio anime,  highly detailed\",\n",
        "\"Negative\" : \"photo, deformed, black and white, realism, disfigured, low contrast\",\n",
        "},\n",
        "\"Photographic\" : {\n",
        "\"Positive\" : \"cinematic photo {prompt} . 35mm photograph, film, bokeh, professional, 4k, highly detailed\",\n",
        "\"Negative\" : \"drawing, painting, crayon, sketch, graphite, impressionist, noisy, blurry, soft, deformed, ugly\",\n",
        "},\n",
        "\"Digital art\" : {\n",
        "\"Positive\" : \"concept art {prompt} . digital artwork, illustrative, painterly, matte painting, highly detailed\",\n",
        "\"Negative\" : \"photo, photorealistic, realism, ugly\",\n",
        "},\n",
        "\"Comic book\" : {\n",
        "\"Positive\" : \"comic {prompt} . graphic illustration, comic art, graphic novel art, vibrant, highly detailed\",\n",
        "\"Negative\" : \"photograph, deformed, glitch, noisy, realistic, stock photo\",\n",
        "},\n",
        "\"Fantasy art\" : {\n",
        "\"Positive\" : \"ethereal fantasy concept art of  {prompt} . magnificent, celestial, ethereal, painterly, epic, majestic, magical, fantasy art, cover art, dreamy\",\n",
        "\"Negative\" : \"photographic, realistic, realism, 35mm film, dslr, cropped, frame, text, deformed, glitch, noise, noisy, off-center, deformed, cross-eyed, closed eyes, bad anatomy, ugly, disfigured, sloppy, duplicate, mutated, black and white\",\n",
        "},\n",
        "\"Analog film\" : {\n",
        "\"Positive\" : \"analog film photo {prompt} . faded film, desaturated, 35mm photo, grainy, vignette, vintage, Kodachrome, Lomography, stained, highly detailed, found footage\",\n",
        "\"Negative\" : \"painting, drawing, illustration, glitch, deformed, mutated, cross-eyed, ugly, disfigured\",\n",
        "},\n",
        "\"Neonpunk\" : {\n",
        "\"Positive\" : \"neonpunk style {prompt} . cyberpunk, vaporwave, neon, vibes, vibrant, stunningly beautiful, crisp, detailed, sleek, ultramodern, magenta highlights, dark purple shadows, high contrast, cinematic, ultra detailed, intricate, professional\",\n",
        "\"Negative\" : \"painting, drawing, illustration, glitch, deformed, mutated, cross-eyed, ugly, disfigured\",\n",
        "},\n",
        "\"Isometric\" : {\n",
        "\"Positive\" : \"isometric style {prompt} . vibrant, beautiful, crisp, detailed, ultra detailed, intricate\",\n",
        "\"Negative\" : \"deformed, mutated, ugly, disfigured, blur, blurry, noise, noisy, realistic, photographic\",\n",
        "},\n",
        "\"Lowpoly\" : {\n",
        "\"Positive\" : \"low-poly style {prompt} . low-poly game art, polygon mesh, jagged, blocky, wireframe edges, centered composition\",\n",
        "\"Negative\" : \"noisy, sloppy, messy, grainy, highly detailed, ultra textured, photo\",\n",
        "},\n",
        "\"Origami\" : {\n",
        "\"Positive\" : \"origami style {prompt} . paper art, pleated paper, folded, origami art, pleats, cut and fold, centered composition\",\n",
        "\"Negative\" : \"noisy, sloppy, messy, grainy, highly detailed, ultra textured, photo\",\n",
        "},\n",
        "\"Line art\" : {\n",
        "\"Positive\" : \"line art drawing {prompt} . professional, sleek, modern, minimalist, graphic, line art, vector graphics\",\n",
        "\"Negative\" : \"anime, photorealistic, 35mm film, deformed, glitch, blurry, noisy, off-center, deformed, cross-eyed, closed eyes, bad anatomy, ugly, disfigured, mutated, realism, realistic, impressionism, expressionism, oil, acrylic\",\n",
        "},\n",
        "\"Craft clay\" : {\n",
        "\"Positive\" : \"play-doh style {prompt} . sculpture, clay art, centered composition, Claymation\",\n",
        "\"Negative\" : \"sloppy, messy, grainy, highly detailed, ultra textured, photo\",\n",
        "},\n",
        "\"Cinematic\" : {\n",
        "\"Positive\" : \"cinematic film still {prompt} . shallow depth of field, vignette, highly detailed, high budget Hollywood movie, bokeh, cinemascope, moody, epic, gorgeous, film grain, grainy\",\n",
        "\"Negative\" : \"anime, cartoon, graphic, text, painting, crayon, graphite, abstract, glitch, deformed, mutated, ugly, disfigured\",\n",
        "},\n",
        "\"3d-model\" : {\n",
        "\"Positive\" : \"professional 3d model {prompt} . octane render, highly detailed, volumetric, dramatic lighting\",\n",
        "\"Negative\" : \"ugly, deformed, noisy, low poly, blurry, painting\",\n",
        "},\n",
        "\"Pixel art\" : {\n",
        "\"Positive\" : \"pixel-art {prompt} . low-res, blocky, pixel art style, 8-bit graphics\",\n",
        "\"Negative\" : \"sloppy, messy, blurry, noisy, highly detailed, ultra textured, photo, realistic\",\n",
        "},\n",
        "\"Texture\" : {\n",
        "\"Positive\" : \"texture {prompt} top down close-up\",\n",
        "\"Negative\" : \"ugly, deformed, noisy, blurry\",\n",
        "}\n",
        "}\n",
        "\n",
        "aspects = {\n",
        "\"12:5\" :  { 'x' : 1536  , 'y' :  640 },\n",
        "\"7:4\" :   { 'x' : 1344  , 'y' :  768 },\n",
        "\"19:13\" : { 'x' : 1216  , 'y' :  832  },\n",
        "\"9:7\" :   { 'x' : 1152 , 'y' : 896  },\n",
        "\"1:1\" :   { 'x' : 1024 , 'y' : 1024 },\n",
        "\"7:9\" :   { 'x' : 896  , 'y' : 1152  },\n",
        "\"13:19\" : { 'x' : 832  , 'y' :  1216 },\n",
        "\"4:7\" :   { 'x' : 768  , 'y' :  1344 },\n",
        "\"5:12\" :  { 'x' : 640  , 'y' :  1536 }\n",
        "}\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "bG2hkmSEvByV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"Gemma Chan as a skyrim character in a film version of Skyrim\"\n",
        "image_count = 4\n",
        "use_refiner = True\n",
        "base_refiner_split=0.8\n",
        "num_inference_steps=45\n",
        "style = \"Cinematic\"\n",
        "aspect = \"19:13\"\n",
        "\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "base_output = []\n",
        "prompt_details = []\n",
        "generators = []\n",
        "\n",
        "orig_prompt = prompt\n",
        "prompt = styles[style][\"Positive\"].replace(\"{prompt}\", prompt)\n",
        "negative_prompt = styles[style][\"Negative\"]\n",
        "\n",
        "text_encoder =  CLIPTextModel.from_pretrained('stabilityai/stable-diffusion-xl-base-1.0',\n",
        "                                              subfolder = 'text_encoder',\n",
        "                                              torch_dtype=torch.float16,\n",
        "                                              use_safetensors=True,\n",
        "                                              variant=\"fp16\", ).to('cuda')\n",
        "\n",
        "text_encoder_2 =  CLIPTextModelWithProjection.from_pretrained('stabilityai/stable-diffusion-xl-base-1.0',\n",
        "                                                              subfolder = 'text_encoder_2',\n",
        "                                                              torch_dtype=torch.float16,\n",
        "                                                              use_safetensors=True,\n",
        "                                                              variant=\"fp16\",).to('cuda')\n",
        "\n",
        "tokenizer =  CLIPTokenizer.from_pretrained('stabilityai/stable-diffusion-xl-base-1.0',\n",
        "                                            subfolder = 'tokenizer',\n",
        "                                            torch_dtype=torch.float16,\n",
        "                                            use_safetensors=True,\n",
        "                                            variant=\"fp16\",)\n",
        "\n",
        "tokenizer_2 = CLIPTokenizer.from_pretrained('stabilityai/stable-diffusion-xl-base-1.0',\n",
        "                                            subfolder='tokenizer_2',\n",
        "                                            torch_dtype=torch.float16,\n",
        "                                            use_safetensors=True,\n",
        "                                            variant=\"fp16\",)\n",
        "\n",
        "compel = Compel(tokenizer=[tokenizer, tokenizer_2] ,\n",
        "                text_encoder=[text_encoder, text_encoder_2],\n",
        "                returned_embeddings_type=ReturnedEmbeddingsType.PENULTIMATE_HIDDEN_STATES_NON_NORMALIZED,\n",
        "                requires_pooled=[False, True])\n",
        "\n",
        "conditioning, pooled = compel(prompt)\n",
        "neg_conditioning, neg_pooled = compel(negative_prompt)\n",
        "\n",
        "compel = None\n",
        "text_encoder =  None\n",
        "tokenizer =  None\n",
        "if use_refiner is False:\n",
        "   tokenizer_2 = None\n",
        "   text_encoder_2 =  None\n",
        "\n",
        "\n",
        "if pipe is None:\n",
        "\n",
        "  refiner = None\n",
        "  gc.collect()\n",
        "  torch.cuda.empty_cache()\n",
        "\n",
        "  pipe = DiffusionPipeline.from_pretrained(\n",
        "      \"stabilityai/stable-diffusion-xl-base-1.0\",\n",
        "      torch_dtype=torch.float16,\n",
        "      use_safetensors=True,\n",
        "      variant=\"fp16\",\n",
        "      vae=vae,\n",
        "      text_encoder=None,\n",
        "      text_encoder_2=None,\n",
        "      tokenizer=None,\n",
        "      tokenizer_2=None,\n",
        "      ).to('cuda')\n",
        "\n",
        "  pipe.scheduler = UniPCMultistepScheduler.from_config(pipe.scheduler.config)\n",
        "  pipe.enable_vae_tiling()\n",
        "\n",
        "  gc.collect()\n",
        "\n",
        "\n",
        "base_output = []\n",
        "prompt_details = []\n",
        "\n",
        "for i in range(image_count):\n",
        "\n",
        "  seed = random.randint(0, sys.maxsize)\n",
        "  generator =  torch.Generator(\"cuda\").manual_seed(seed);\n",
        "\n",
        "  kwargs = {\n",
        "      'prompt_embeds':conditioning,\n",
        "      'pooled_prompt_embeds':pooled,\n",
        "      'negative_prompt_embeds':neg_conditioning,\n",
        "      'negative_pooled_prompt_embeds':neg_pooled,\n",
        "      'output_type': \"latent\" if use_refiner else \"pil\",\n",
        "      'generator':generator,\n",
        "      'num_inference_steps':num_inference_steps,\n",
        "      'width': aspects[aspect]['x'],\n",
        "      'height': aspects[aspect]['y'],\n",
        "  }\n",
        "\n",
        "  if use_refiner:\n",
        "    kwargs['denoising_end'] = base_refiner_split\n",
        "\n",
        "  images = pipe(**kwargs).images\n",
        "\n",
        "  if use_refiner:\n",
        "    generators.append(generator)\n",
        "    base_output.append(images)\n",
        "    prompt_details.append(f\"Prompt:\\t{orig_prompt}\\nStyle:\\t{style}\\nSeed:\\t{seed}\")\n",
        "  else:\n",
        "    print(f\"Prompt:\\t{orig_prompt}\\nStyle:\\t{style}\\nSeed:\\t{seed}\")\n",
        "    media.show_images(images)\n",
        "\n",
        "if use_refiner:\n",
        "\n",
        "  pipe = None\n",
        "  gc.collect()\n",
        "  torch.cuda.empty_cache()\n",
        "\n",
        "  refiner = DiffusionPipeline.from_pretrained(\n",
        "      \"stabilityai/stable-diffusion-xl-refiner-1.0\",\n",
        "      vae=vae,\n",
        "      torch_dtype=torch.float16,\n",
        "      use_safetensors=True,\n",
        "      variant=\"fp16\",\n",
        "  ).to('cuda')\n",
        "\n",
        "  refiner.scheduler = UniPCMultistepScheduler.from_config(refiner.scheduler.config)\n",
        "\n",
        "  refiner.enable_vae_tiling()\n",
        "\n",
        "  compel = Compel(tokenizer=[tokenizer_2] ,\n",
        "                          text_encoder=[text_encoder_2],\n",
        "                          returned_embeddings_type=ReturnedEmbeddingsType.PENULTIMATE_HIDDEN_STATES_NON_NORMALIZED,\n",
        "                          requires_pooled=[True])\n",
        "\n",
        "\n",
        "  conditioning, pooled = compel(prompt)\n",
        "  neg_conditioning, neg_pooled = compel(negative_prompt)\n",
        "  compel = None\n",
        "\n",
        "  gc.collect()\n",
        "\n",
        "\n",
        "  for i in range(image_count):\n",
        "\n",
        "\n",
        "    if use_refiner:\n",
        "      images = refiner(\n",
        "          prompt_embeds=conditioning,\n",
        "          pooled_prompt_embeds=pooled,\n",
        "          negative_prompt_embeds=neg_conditioning,\n",
        "          negative_pooled_prompt_embeds=neg_pooled,\n",
        "          image = base_output[i],\n",
        "          num_inference_steps=num_inference_steps,\n",
        "          denoising_start = base_refiner_split,\n",
        "          generator = generator,\n",
        "          ).images\n",
        "\n",
        "    print(prompt_details[i])\n",
        "    media.show_images(images)\n",
        "\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "AUc4QJfE-uR9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}